{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import os\n",
    "import time\n",
    "import warnings\n",
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "import torch.utils.data\n",
    "import torchvision\n",
    "import utils\n",
    "from torch import nn\n",
    "from torch.utils.data.dataloader import default_collate\n",
    "import torchvision.transforms as transforms\n",
    "from tiny_imagenet_dataset import TinyImageNet\n",
    "from imagenet_ipc import ImageFolderIPC\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "from types import SimpleNamespace\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1'\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"torch.optim.lr_scheduler\")\n",
    "\n",
    "args = {\n",
    "    'dataset': 'tiny',\n",
    "    \"workers\": 4,\n",
    "    \"image_per_class\": 100,             #number of synthetic images per class\n",
    "    \"batch_size\": 64,\n",
    "    'data_path': './Datasets/Tiny-ImageNet/',    # path of the original dataset\n",
    "    \"filter_model\": \"resnet18\",         # filter model in each curriculum\n",
    "    \"teacher_model\": \"resnet18\",        # teacher model name\n",
    "    \"teacher_path\": \"./checkpoints/resnet18_tiny_200epochs.pth\",   # teacher model checkpoint path\n",
    "    \"eval_model\": \"resnet18\",           # model for final evaluation\n",
    "    \"device\": \"cuda\",\n",
    "    \"epochs\": 100,                      # training epochs for both the filter and the evaluation model\n",
    "    \"opt\": \"sgd\",\n",
    "    \"lr\": 0.2,\n",
    "    \"momentum\": 0.9,\n",
    "    \"weight_decay\": 1e-4,\n",
    "    \"lr_scheduler\": \"cosineannealinglr\",\n",
    "    \"lr_warmup_epochs\": 5,\n",
    "    \"lr_warmup_method\": \"linear\",\n",
    "    \"lr_warmup_decay\": 0.01,\n",
    "    \"lr_step_size\": 30,\n",
    "    \"print_freq\": 2000,\n",
    "    \"start_epoch\": 0,\n",
    "    \"temperature\": 20,                  # temperature for distillation loss\n",
    "    \"distill_data_path\": \"./syn-data/cda_tiny_rn18_ipc200\",     # already distilled data by CDA approach\n",
    "    \"alpha\": 0.2,                       # distillation portion\n",
    "    \"curriculum_num\": 3,                # number of curricula\n",
    "    \"select_misclassified\": True,       # strategy in coarse stage\n",
    "    \"select_method\": \"simple\",          # strategy in fine stage\n",
    "    \"balance\": True,                    # whether to balance the amount of the synthetic data between classes\n",
    "    \"score\": \"forgetting\",              # difficulty score used in fine stage\n",
    "    \"output_dir\": \"./logs\"\n",
    "}\n",
    "args = SimpleNamespace(**args)\n",
    "\n",
    "def load_data(args):\n",
    "    # Data loading code\n",
    "    normalize = transforms.Normalize(mean=[0.4802, 0.4481, 0.3975],\n",
    "                                     std=[0.2302, 0.2265, 0.2262])\n",
    "    print(\"Loading distilled data\")\n",
    "    train_transform = transforms.Compose([\n",
    "            transforms.RandomResizedCrop(64),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.ToTensor(),\n",
    "            normalize,\n",
    "        ])\n",
    "\n",
    "    dataset = ImageFolderIPC(root=args.distill_data_path, ipc=args.cpc, transform=train_transform)\n",
    "        \n",
    "    print(\"Loading validation data\")\n",
    "    val_transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        normalize,\n",
    "    ])\n",
    "    dataset_test = TinyImageNet(args.data_path, split='val', download=True, transform=val_transform)\n",
    "\n",
    "    print(\"Loading original training data\")\n",
    "    dataset_og = TinyImageNet(args.data_path, split='train', download=True, transform=val_transform)\n",
    "    images_og = [torch.unsqueeze(dataset_og[i][0], dim=0) for i in range(len(dataset_og))]\n",
    "    labels_og = [dataset_og[i][1] for i in range(len(dataset_og))]\n",
    "    images_og = torch.cat(images_og, dim=0)\n",
    "    labels_og = torch.tensor(labels_og, dtype=torch.long)\n",
    "\n",
    "    print(\"Creating data loaders\")\n",
    "    train_sampler = torch.utils.data.RandomSampler(dataset)\n",
    "    test_sampler = torch.utils.data.SequentialSampler(dataset_test)\n",
    "\n",
    "    return dataset, images_og, labels_og, dataset_test, train_sampler, test_sampler\n",
    "\n",
    "def curriculum_arrangement(spc, curriculum_num):\n",
    "    remainder = spc % curriculum_num\n",
    "    arrangement = [spc // curriculum_num] * curriculum_num\n",
    "    for i in range(remainder):\n",
    "        arrangement[i] += 1\n",
    "\n",
    "    return arrangement\n",
    "\n",
    "\n",
    "def train_one_epoch(model, teacher_model, criterion, optimizer, data_loader, device, epoch, args):\n",
    "    model.train()\n",
    "    teacher_model.eval()\n",
    "    metric_logger = utils.MetricLogger(delimiter=\"  \")\n",
    "    metric_logger.add_meter(\"lr\", utils.SmoothedValue(window_size=1, fmt=\"{value}\"))\n",
    "    metric_logger.add_meter(\"img/s\", utils.SmoothedValue(window_size=10, fmt=\"{value}\"))\n",
    "\n",
    "    header = f\"Epoch: [{epoch}]\"\n",
    "    for i, (image, target) in enumerate(metric_logger.log_every(data_loader, args.print_freq, header)):\n",
    "        start_time = time.time()\n",
    "        image, target = image.to(device), target.to(device)\n",
    "        teacher_output = teacher_model(image)\n",
    "        output = model(image)\n",
    "        teacher_output_log_softmax = F.log_softmax(teacher_output/args.temperature, dim=1)\n",
    "        output_log_softmax = F.log_softmax(output/args.temperature, dim=1)\n",
    "        loss = criterion(output_log_softmax, teacher_output_log_softmax) * (args.temperature ** 2)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        acc1, acc5 = utils.accuracy(output, target, topk=(1, 5))\n",
    "        batch_size = image.shape[0]\n",
    "        metric_logger.update(loss=loss.item(), lr=optimizer.param_groups[0][\"lr\"])\n",
    "        metric_logger.meters[\"acc1\"].update(acc1.item(), n=batch_size)\n",
    "        metric_logger.meters[\"acc5\"].update(acc5.item(), n=batch_size)\n",
    "        metric_logger.meters[\"img/s\"].update(batch_size / (time.time() - start_time))\n",
    "\n",
    "def evaluate(model, criterion, data_loader, device, log_suffix=\"\"):\n",
    "    model.eval()\n",
    "    metric_logger = utils.MetricLogger(delimiter=\"  \")\n",
    "    header = f\"Test: {log_suffix}\"\n",
    "\n",
    "    num_processed_samples = 0\n",
    "    with torch.inference_mode():\n",
    "        for image, target in data_loader:\n",
    "            image = image.to(device, non_blocking=True)\n",
    "            target = target.to(device, non_blocking=True)\n",
    "            output = model(image)\n",
    "            loss = criterion(output, target)\n",
    "\n",
    "            acc1, acc5 = utils.accuracy(output, target, topk=(1, 5))\n",
    "            # FIXME need to take into account that the datasets\n",
    "            # could have been padded in distributed setup\n",
    "            batch_size = image.shape[0]\n",
    "            metric_logger.update(loss=loss.item())\n",
    "            metric_logger.meters[\"acc1\"].update(acc1.item(), n=batch_size)\n",
    "            metric_logger.meters[\"acc5\"].update(acc5.item(), n=batch_size)\n",
    "            num_processed_samples += batch_size\n",
    "    # gather the stats from all processes\n",
    "\n",
    "    num_processed_samples = utils.reduce_across_processes(num_processed_samples)\n",
    "    if (\n",
    "        hasattr(data_loader.dataset, \"__len__\")\n",
    "        and len(data_loader.dataset) != num_processed_samples\n",
    "        and torch.distributed.get_rank() == 0\n",
    "    ):\n",
    "        warnings.warn(\n",
    "            f\"It looks like the dataset has {len(data_loader.dataset)} samples, but {num_processed_samples} \"\n",
    "            \"samples were used for the validation, which might bias the results. \"\n",
    "            \"Try adjusting the batch size and / or the world size. \"\n",
    "            \"Setting the world size to 1 is always a safe bet.\"\n",
    "        )\n",
    "\n",
    "    metric_logger.synchronize_between_processes()\n",
    "\n",
    "    # print(f\"{header} Acc@1 {metric_logger.acc1.global_avg:.3f} Acc@5 {metric_logger.acc5.global_avg:.3f}\")\n",
    "    return metric_logger.acc1.global_avg\n",
    "\n",
    "def curriculum_train(current_curriculum, dst_train, test_loader, model, teacher_model, args):\n",
    "    best_acc1 = 0\n",
    "    \n",
    "    train_sampler = torch.utils.data.RandomSampler(dst_train)\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        dst_train,\n",
    "        batch_size=args.batch_size,\n",
    "        sampler=train_sampler,\n",
    "        num_workers=args.workers,\n",
    "        pin_memory=True,\n",
    "    )\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    criterion_kl = nn.KLDivLoss(reduction='batchmean', log_target=True)\n",
    "    \n",
    "    parameters = utils.set_weight_decay(model, args.weight_decay)\n",
    "    \n",
    "    opt_name = args.opt.lower()\n",
    "    if opt_name.startswith(\"sgd\"):\n",
    "        optimizer = torch.optim.SGD(\n",
    "            parameters,\n",
    "            lr=args.lr,\n",
    "            momentum=args.momentum,\n",
    "            weight_decay=args.weight_decay,\n",
    "            nesterov=\"nesterov\" in opt_name,\n",
    "        )\n",
    "    elif opt_name == \"rmsprop\":\n",
    "        optimizer = torch.optim.RMSprop(\n",
    "            parameters, lr=args.lr, momentum=args.momentum, weight_decay=args.weight_decay, eps=0.0316, alpha=0.9\n",
    "        )\n",
    "    elif opt_name == \"adamw\":\n",
    "        optimizer = torch.optim.AdamW(parameters, lr=args.lr, weight_decay=args.weight_decay)\n",
    "    else:\n",
    "        raise RuntimeError(f\"Invalid optimizer {args.opt}. Only SGD, RMSprop and AdamW are supported.\")\n",
    "\n",
    "    args.lr_scheduler = args.lr_scheduler.lower()\n",
    "    if args.lr_scheduler == \"steplr\":\n",
    "        main_lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=args.lr_step_size, gamma=args.lr_gamma)\n",
    "    elif args.lr_scheduler == \"cosineannealinglr\":\n",
    "        main_lr_scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
    "            optimizer, T_max=args.epochs - args.lr_warmup_epochs, eta_min=0.0\n",
    "        )\n",
    "    elif args.lr_scheduler == \"exponentiallr\":\n",
    "        main_lr_scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=args.lr_gamma)\n",
    "    else:\n",
    "        raise RuntimeError(\n",
    "            f\"Invalid lr scheduler '{args.lr_scheduler}'. Only StepLR, CosineAnnealingLR and ExponentialLR \"\n",
    "            \"are supported.\"\n",
    "        )\n",
    "\n",
    "    if args.lr_warmup_epochs > 0:\n",
    "        if args.lr_warmup_method == \"linear\":\n",
    "            warmup_lr_scheduler = torch.optim.lr_scheduler.LinearLR(\n",
    "                optimizer, start_factor=args.lr_warmup_decay, total_iters=args.lr_warmup_epochs\n",
    "            )\n",
    "        elif args.lr_warmup_method == \"constant\":\n",
    "            warmup_lr_scheduler = torch.optim.lr_scheduler.ConstantLR(\n",
    "                optimizer, factor=args.lr_warmup_decay, total_iters=args.lr_warmup_epochs\n",
    "            )\n",
    "        else:\n",
    "            raise RuntimeError(\n",
    "                f\"Invalid warmup lr method '{args.lr_warmup_method}'. Only linear and constant are supported.\"\n",
    "            )\n",
    "        lr_scheduler = torch.optim.lr_scheduler.SequentialLR(\n",
    "            optimizer, schedulers=[warmup_lr_scheduler, main_lr_scheduler], milestones=[args.lr_warmup_epochs]\n",
    "        )\n",
    "    else:\n",
    "        lr_scheduler = main_lr_scheduler\n",
    "        \n",
    "    print(\"Start training on synthetic dataset...\")\n",
    "    start_time = time.time()\n",
    "    pbar = tqdm(range(args.start_epoch, args.epochs), ncols=100)\n",
    "    for epoch in pbar:\n",
    "        train_one_epoch(model, teacher_model, criterion_kl, optimizer, train_loader, args.device, epoch, args)\n",
    "        lr_scheduler.step()\n",
    "        # if epoch % 10 == 0 or epoch == args.epochs - 1 or current_curriculum == args.curriculum_num:\n",
    "        #     acc1 = evaluate(model, criterion, test_loader, device=args.device)\n",
    "        #     if acc1 > best_acc1:\n",
    "        #         best_acc1 = acc1\n",
    "        #     pbar.set_description(f\"Epoch[{epoch}] Test Acc: {acc1:.2f}% Best Acc: {best_acc1:.2f}%\")\n",
    "        if epoch > args.epochs * 0.8:\n",
    "            acc1 = evaluate(model, criterion, test_loader, device=args.device)\n",
    "            if acc1 > best_acc1:\n",
    "                best_acc1 = acc1\n",
    "            pbar.set_description(f\"Epoch[{epoch}] Test Acc: {acc1:.2f}% Best Acc: {best_acc1:.2f}%\")\n",
    "    print(f\"Best Accuracy {best_acc1:.2f}%\")\n",
    "    total_time = time.time() - start_time\n",
    "    total_time_str = str(datetime.timedelta(seconds=int(total_time)))\n",
    "    print(f\"Training time {total_time_str}\")\n",
    "    \n",
    "    return model, best_acc1\n",
    "\n",
    "def coarse_filtering(images_all, labels_all, filter, batch_size, args, get_correct=True):\n",
    "    true_labels = labels_all.cpu()\n",
    "    filter.eval()\n",
    "    logits = None\n",
    "    for select_times in range((len(images_all)+batch_size-1)//batch_size):\n",
    "        current_data_batch = images_all[batch_size*select_times : batch_size*(select_times+1)].detach().to(args.device)\n",
    "        batch_logits = filter(current_data_batch)\n",
    "        if logits == None:\n",
    "            logits = batch_logits.detach()\n",
    "        else:\n",
    "            logits = torch.cat((logits, batch_logits.detach()),0)\n",
    "    predicted_labels = torch.argmax(logits, dim=1).cpu()\n",
    "    target_indices = torch.where(true_labels == predicted_labels)[0] if get_correct else torch.where(true_labels != predicted_labels)[0]\n",
    "    target_indices = target_indices.tolist()\n",
    "    print('Acc on training set: {:.2f}%'.format(100*len(target_indices)/len(images_all) if get_correct else 100*(1-len(target_indices)/len(images_all))))\n",
    "    return target_indices, logits\n",
    "\n",
    "def selection_logits(selected_idx, teacher_correct_idx, images_all, labels_all, filter, args):\n",
    "    batch_size = 256\n",
    "    true_labels = labels_all.cpu()\n",
    "    filter.eval()\n",
    "    print('Coarse Filtering...')\n",
    "    if args.select_misclassified:\n",
    "        target_indices, logits = coarse_filtering(images_all, labels_all, filter, batch_size, args, get_correct=False)\n",
    "    else:\n",
    "        target_indices, logits = coarse_filtering(images_all, labels_all, filter, batch_size, args, get_correct=True)\n",
    "    \n",
    "    if teacher_correct_idx is not None:\n",
    "        target_indices = list(set(teacher_correct_idx) & set(target_indices) - set(selected_idx))\n",
    "    else:\n",
    "        target_indices = list(set(target_indices) - set(selected_idx))\n",
    "    print('Fine Selection...')\n",
    "    selection = []\n",
    "    if args.balance:\n",
    "        target_idx_per_class = [[] for c in range(args.num_classes)]\n",
    "        for idx in target_indices:\n",
    "            target_idx_per_class[true_labels[idx]].append(idx)\n",
    "        for c in range(args.num_classes):\n",
    "            if args.select_method == 'random':\n",
    "                selection += random.sample(target_idx_per_class[c], args.curpc)\n",
    "            elif args.select_method == 'hard':\n",
    "                selection += sorted(target_idx_per_class[c], key=lambda i: logits[i][c], reverse=False)[:args.curpc]\n",
    "            elif args.select_method == 'simple':\n",
    "                selection += sorted(target_idx_per_class[c], key=lambda i: logits[i][c], reverse=True)[:args.curpc]\n",
    "    else:\n",
    "        if args.select_method == 'random':\n",
    "            selection = random.sample(target_indices, args.curpc*args.num_classes)\n",
    "        elif args.select_method == 'hard':\n",
    "            selection = sorted(target_indices, key=lambda i: logits[i][true_labels[i]], reverse=False)[:args.curpc*args.num_classes]\n",
    "        elif args.select_method == 'simple':\n",
    "            selection = sorted(target_indices, key=lambda i: logits[i][true_labels[i]], reverse=True)[:args.curpc*args.num_classes]\n",
    "\n",
    "    return selection\n",
    "\n",
    "def selection_score(selected_idx, teacher_correct_idx, images_all, labels_all, filter, score, reverse, args):\n",
    "    batch_size = 256\n",
    "    true_labels = labels_all.cpu()\n",
    "    filter.eval()\n",
    "    \n",
    "    print('Coarse Filtering...')\n",
    "    if args.select_misclassified:\n",
    "        target_indices, _ = coarse_filtering(images_all, labels_all, filter, batch_size, args, get_correct=False)\n",
    "    else:\n",
    "        target_indices, _ = coarse_filtering(images_all, labels_all, filter, batch_size, args, get_correct=True)\n",
    "    \n",
    "    if teacher_correct_idx is not None:\n",
    "        target_indices = list(set(teacher_correct_idx) & set(target_indices) - set(selected_idx))\n",
    "    else:\n",
    "        target_indices = list(set(target_indices) - set(selected_idx))\n",
    "    print('Fine Selection...')\n",
    "    selection = []\n",
    "    if args.balance:\n",
    "        target_idx_per_class = [[] for c in range(args.num_classes)]\n",
    "        for idx in target_indices:\n",
    "            target_idx_per_class[true_labels[idx]].append(idx)\n",
    "        for c in range(args.num_classes):\n",
    "            if args.select_method == 'random':\n",
    "                selection += random.sample(target_idx_per_class[c], min(args.curpc, len(target_idx_per_class[c])))\n",
    "            elif args.select_method == 'hard':\n",
    "                selection += sorted(target_idx_per_class[c], key=lambda i: score[i], reverse=reverse)[:args.curpc]\n",
    "            elif args.select_method == 'simple':\n",
    "                selection += sorted(target_idx_per_class[c], key=lambda i: score[i], reverse=not reverse)[:args.curpc]\n",
    "    else:\n",
    "        if args.select_method == 'random':\n",
    "            selection = random.sample(target_indices, min(args.curpc*args.num_classes, len(target_indices)))\n",
    "        elif args.select_method == 'hard':\n",
    "            selection = sorted(target_indices, key=lambda i: score[i], reverse=reverse)[:args.curpc*args.num_classes]\n",
    "        elif args.select_method == 'simple':\n",
    "            selection = sorted(target_indices, key=lambda i: score[i], reverse=not reverse)[:args.curpc*args.num_classes]\n",
    "            \n",
    "    return selection\n",
    "\n",
    "def create_model(model_name, device, path=None):\n",
    "    model = torchvision.models.get_model(model_name, weights=None, num_classes=args.num_classes)\n",
    "    model.conv1 = nn.Conv2d(3,64, kernel_size=(3,3), stride=(1,1), padding=(1,1), bias=False)\n",
    "    model.maxpool = nn.Identity()\n",
    "    if path is not None:\n",
    "        checkpoint = torch.load(path, map_location=\"cpu\")\n",
    "        if \"model\" in checkpoint:\n",
    "            checkpoint = checkpoint[\"model\"]\n",
    "        elif \"state_dict\" in checkpoint:\n",
    "            checkpoint = checkpoint[\"state_dict\"]\n",
    "        if \"module.\" in list(checkpoint.keys())[0]:\n",
    "            checkpoint = {k.replace(\"module.\", \"\"): v for k, v in checkpoint.items()}\n",
    "        model.load_state_dict(checkpoint)\n",
    "    model.to(device)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target IPC: 100, num_classes: 200, distillation portion: 0.2, distilled images per class: 20, real images to be selected per class: 80\n",
      "Loading distilled data\n",
      "Loading validation data\n",
      "Files already downloaded and verified.\n",
      "Loading original training data\n",
      "Files already downloaded and verified.\n",
      "Creating data loaders\n",
      "Acc on training set: 99.42%\n",
      "teacher acc@1 on original training data: 99.42%\n"
     ]
    }
   ],
   "source": [
    "'''Preparation'''\n",
    "if args.output_dir:\n",
    "    utils.mkdir(os.path.join(args.output_dir, 'Tiny'))\n",
    "device = torch.device(args.device)\n",
    "torch.backends.cudnn.benchmark = True\n",
    "args.cpc = int(args.image_per_class * args.alpha)   # condensed images per class\n",
    "args.spc = args.image_per_class - args.cpc          # selected real images per class\n",
    "args.num_classes = 200\n",
    "print('Target IPC: {}, num_classes: {}, distillation portion: {}, distilled images per class: {}, real images to be selected per class: {}'\n",
    "      .format(args.image_per_class, args.num_classes, args.alpha, args.cpc, args.spc))\n",
    "dataset_dis, images_og, labels_og, dataset_test, train_sampler, test_sampler = load_data(args)\n",
    "if args.score == 'forgetting':\n",
    "    score = np.load(f'./scores/forgetting_Tiny.npy')\n",
    "    reverse = True\n",
    "curriculum_num = args.curriculum_num\n",
    "arrangement = curriculum_arrangement(args.spc, curriculum_num)\n",
    "test_loader = torch.utils.data.DataLoader(dataset_test, batch_size=256, sampler=test_sampler, num_workers=args.workers, pin_memory=True)\n",
    "\n",
    "teacher_model = create_model(args.teacher_model, device, args.teacher_path)\n",
    "for p in teacher_model.parameters():\n",
    "    p.requires_grad = False\n",
    "teacher_model.eval()\n",
    "teacher_correct_idx, _ = coarse_filtering(images_og, labels_og, teacher_model, 256, args, get_correct=True)\n",
    "print('teacher acc@1 on original training data: {:.2f}%'.format(100*len(teacher_correct_idx)/len(images_og)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected images per class arrangement in each curriculum:  [27, 27, 26]\n",
      "----Curriculum [1/3]----\n",
      "Begin with distilled dataset\n",
      "Synthetic dataset size: 4000 distilled data: 4000 selected data: 0\n",
      "Start training on synthetic dataset...\n",
      "Epoch[99] Test Acc: 30.87% Best Acc: 31.53%: 100%|████████████████| 100/100 [06:07<00:00,  3.67s/it]\n",
      "Best Accuracy 31.53%\n",
      "Training time 0:06:07\n",
      "Selecting real data...\n",
      "Coarse Filtering...\n",
      "Acc on training set: 33.64%\n",
      "Fine Selection...\n",
      "Selected 5400 in this curriculum\n",
      "----Curriculum [2/3]----\n",
      "Synthetic dataset size: 9400 distilled data: 4000 selected data: 5400\n",
      "Start training on synthetic dataset...\n",
      "Epoch[99] Test Acc: 53.11% Best Acc: 53.11%: 100%|████████████████| 100/100 [10:43<00:00,  6.44s/it]\n",
      "Best Accuracy 53.11%\n",
      "Training time 0:10:43\n",
      "Selecting real data...\n",
      "Coarse Filtering...\n",
      "Acc on training set: 59.97%\n",
      "Fine Selection...\n",
      "Selected 5400 in this curriculum\n",
      "----Curriculum [3/3]----\n",
      "Synthetic dataset size: 14800 distilled data: 4000 selected data: 10800\n",
      "Start training on synthetic dataset...\n",
      "Epoch[99] Test Acc: 57.91% Best Acc: 58.01%: 100%|████████████████| 100/100 [15:25<00:00,  9.25s/it]\n",
      "Best Accuracy 58.01%\n",
      "Training time 0:15:25\n",
      "Selecting real data...\n",
      "Coarse Filtering...\n",
      "Acc on training set: 67.58%\n",
      "Fine Selection...\n",
      "Selected 5200 in this curriculum\n",
      "----All curricula finished----\n",
      "Final synthetic dataset size: 20000 distilled data: 4000 selected data: 16000\n"
     ]
    }
   ],
   "source": [
    "'''Curriculum selection'''\n",
    "idx_selected = []\n",
    "dataset_sel = None\n",
    "dst_sel_transform = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(64),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "])\n",
    "print('Selected images per class arrangement in each curriculum: ', arrangement)\n",
    "\n",
    "for i in range(curriculum_num):\n",
    "    print('----Curriculum [{}/{}]----'.format(i+1, curriculum_num))\n",
    "    args.curpc = arrangement[i]\n",
    "    if i == 0:\n",
    "        print('Begin with distilled dataset')\n",
    "        syn_dataset = dataset_dis\n",
    "        dataset_sel = []\n",
    "    \n",
    "    print('Synthetic dataset size:', len(syn_dataset), \"distilled data:\", len(dataset_dis), \"selected data:\", len(dataset_sel))\n",
    "    filter = create_model(args.filter_model, device)\n",
    "    filter, best_acc1 = curriculum_train(i, syn_dataset, test_loader, filter, teacher_model, args)\n",
    "\n",
    "    print('Selecting real data...')\n",
    "    if args.score == 'logits':\n",
    "        selection = selection_logits(idx_selected, teacher_correct_idx, images_og, labels_og, filter, args)\n",
    "    else:\n",
    "        selection = selection_score(idx_selected, teacher_correct_idx, images_og, labels_og, filter, score, reverse, args)\n",
    "    idx_selected += selection\n",
    "    print('Selected {} in this curriculum'.format(len(selection)))\n",
    "    imgs_select = images_og[idx_selected]\n",
    "    labs_select = labels_og[idx_selected]\n",
    "    dataset_sel = utils.TensorDataset(imgs_select, labs_select, dst_sel_transform)\n",
    "    syn_dataset = torch.utils.data.ConcatDataset([dataset_dis, dataset_sel])\n",
    "print('----All curricula finished----')\n",
    "print('Final synthetic dataset size:', len(syn_dataset), \"distilled data:\", len(dataset_dis), \"selected data:\", len(dataset_sel))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation 1/5\n",
      "Start training on synthetic dataset...\n",
      "Epoch[99] Test Acc: 60.12% Best Acc: 60.18%: 100%|████████████████| 100/100 [20:01<00:00, 12.02s/it]\n",
      "Best Accuracy 60.18%\n",
      "Training time 0:20:01\n",
      "Evaluation 2/5\n",
      "Start training on synthetic dataset...\n",
      "Epoch[99] Test Acc: 59.93% Best Acc: 60.13%: 100%|████████████████| 100/100 [20:02<00:00, 12.02s/it]\n",
      "Best Accuracy 60.13%\n",
      "Training time 0:20:02\n",
      "Evaluation 3/5\n",
      "Start training on synthetic dataset...\n",
      "Epoch[99] Test Acc: 59.52% Best Acc: 59.96%: 100%|████████████████| 100/100 [20:02<00:00, 12.02s/it]\n",
      "Best Accuracy 59.96%\n",
      "Training time 0:20:02\n",
      "Evaluation 4/5\n",
      "Start training on synthetic dataset...\n",
      "Epoch[99] Test Acc: 60.32% Best Acc: 60.48%: 100%|████████████████| 100/100 [20:01<00:00, 12.02s/it]\n",
      "Best Accuracy 60.48%\n",
      "Training time 0:20:01\n",
      "Evaluation 5/5\n",
      "Start training on synthetic dataset...\n",
      "Epoch[99] Test Acc: 60.20% Best Acc: 60.24%: 100%|████████████████| 100/100 [20:03<00:00, 12.04s/it]\n",
      "Best Accuracy 60.24%\n",
      "Training time 0:20:03\n",
      "----Evaluation Results----\n",
      "Acc@1(mean): 60.20%, std: 0.17\n"
     ]
    }
   ],
   "source": [
    "'''Final evaluation'''\n",
    "num_eval = 5\n",
    "accs = []\n",
    "for i in range(num_eval):\n",
    "        print(f'Evaluation {i+1}/{num_eval}')\n",
    "        eval_model = create_model(args.eval_model, device)\n",
    "        _, best_acc1 = curriculum_train(0, syn_dataset, test_loader, eval_model, teacher_model, args)\n",
    "        accs.append(best_acc1)\n",
    "acc_mean = np.mean(accs)\n",
    "acc_std = np.std(accs)\n",
    "print('----Evaluation Results----')\n",
    "print(f'Acc@1(mean): {acc_mean:.2f}%, std: {acc_std:.2f}')   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vldd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
